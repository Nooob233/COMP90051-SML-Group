{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello World! Feel Free to play around for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 1: 加载数据\n",
    "df_y2 = pd.read_csv('../data/train_test/rf_data_Y2.csv')\n",
    "df_y3 = pd.read_csv('../data/train_test/rf_data_Y3.csv')\n",
    "\n",
    "# 假设 'DaysInHospital' 是标签列，'MemberID' 不参与训练\n",
    "X_y2 = df_y2.drop(['DaysInHospital', 'MemberID'], axis=1)\n",
    "y_y2 = df_y2['DaysInHospital']\n",
    "\n",
    "X_y3 = df_y3.drop(['DaysInHospital', 'MemberID'], axis=1)\n",
    "y_y3 = df_y3['DaysInHospital']\n",
    "\n",
    "# Step 2: 实现k折交叉验证\n",
    "def k_fold_cross_validation(X, y, k, model):\n",
    "    np.random.seed(42)\n",
    "    fold_size = len(X) // k\n",
    "    indices = np.random.permutation(len(X))\n",
    "    mse_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        val_indices = indices[i * fold_size: (i + 1) * fold_size]\n",
    "        train_indices = np.concatenate([indices[:i * fold_size], indices[(i + 1) * fold_size:]])\n",
    "\n",
    "        X_train, X_val = X.iloc[train_indices], X.iloc[val_indices]\n",
    "        y_train, y_val = y.iloc[train_indices], y.iloc[val_indices]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    return np.mean(mse_scores), np.std(mse_scores)\n",
    "\n",
    "# Step 3: 实现嵌套交叉验证\n",
    "def nested_cross_validation(X, y, outer_k=3, inner_k=3, param_grid=None):\n",
    "    if param_grid is None:\n",
    "        param_grid = {'n_estimators': [10, 50, 100]}  # 这里只调整 n_estimators\n",
    "\n",
    "    outer_mse_scores = []\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    fold_size_outer = len(X) // outer_k\n",
    "\n",
    "    for i in range(outer_k):\n",
    "        val_indices_outer = indices[i * fold_size_outer:(i + 1) * fold_size_outer]\n",
    "        train_indices_outer = np.concatenate([indices[:i * fold_size_outer], indices[(i + 1) * fold_size_outer:]])\n",
    "\n",
    "        X_train_outer, X_val_outer = X.iloc[train_indices_outer], X.iloc[val_indices_outer]\n",
    "        y_train_outer, y_val_outer = y.iloc[train_indices_outer], y.iloc[val_indices_outer]\n",
    "\n",
    "        best_mse = float('inf')\n",
    "        best_params = None\n",
    "\n",
    "        for n_estimators in param_grid['n_estimators']:\n",
    "            model = RandomForestRegressor(n_estimators=n_estimators, random_state=42, n_jobs=-1)\n",
    "            mean_mse, _ = k_fold_cross_validation(X_train_outer, y_train_outer, inner_k, model)\n",
    "\n",
    "            if mean_mse < best_mse:\n",
    "                best_mse = mean_mse\n",
    "                best_params = {'n_estimators': n_estimators}\n",
    "\n",
    "        final_model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "        final_model.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "        y_pred_outer = final_model.predict(X_val_outer)\n",
    "        mse_outer = mean_squared_error(y_val_outer, y_pred_outer)\n",
    "        outer_mse_scores.append(mse_outer)\n",
    "\n",
    "    return np.mean(outer_mse_scores), np.std(outer_mse_scores), best_params\n",
    "\n",
    "# Step 4: 进行20次独立实验，并计算均值和方差\n",
    "def run_multiple_experiments(X, y, repetitions=20, outer_k=3, inner_k=3, param_grid=None):\n",
    "    mse_results = []\n",
    "    best_param_list = []\n",
    "    for i in range(repetitions):\n",
    "        print(f\"Running repetition {i+1}/{repetitions}\")\n",
    "        mean_mse, std_mse, best_params = nested_cross_validation(X, y, outer_k=outer_k, inner_k=inner_k, param_grid=param_grid)\n",
    "        mse_results.append(mean_mse)\n",
    "        best_param_list.append(best_params)\n",
    "\n",
    "    return np.mean(mse_results), np.std(mse_results), best_param_list\n",
    "\n",
    "# Step 5: 执行嵌套交叉验证实验\n",
    "param_grid = {'n_estimators': [50, 100, 200]}\n",
    "mean_mse, std_mse, best_params_list = run_multiple_experiments(X_y2, y_y2, repetitions=5, param_grid=param_grid)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Mean MSE after 5 repetitions: {mean_mse}\")\n",
    "print(f\"Standard deviation of MSE after 5 repetitions: {std_mse}\")\n",
    "print(f\"Best Parameters: {best_params_list}\")\n",
    "\n",
    "# Step 6: 使用最优模型对第三年数据进行预测并评估\n",
    "best_params = best_params_list[-1]  # 使用最后一次实验的最佳参数\n",
    "final_model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
    "final_model.fit(X_y2, y_y2)\n",
    "\n",
    "y_pred_y3 = final_model.predict(X_y3)\n",
    "\n",
    "# Step 7: 评估模型在第三年数据上的表现\n",
    "mse_y3 = mean_squared_error(y_y3, y_pred_y3)\n",
    "print(f\"Mean Squared Error on Year 3 data: {mse_y3}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('../data/processed/merged_data_Y2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除不用于预测的列，例如 MemberID\n",
    "X = df.drop(columns=['MemberID', 'DaysInHospital'])\n",
    "\n",
    "# 将 DaysInHospital 作为标签\n",
    "y = df['DaysInHospital']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. 特征选择之前的模型\n",
    "# 训练随机森林模型\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 评估特征选择之前的模型性能\n",
    "pre_selection_score = rf.score(X_test, y_test)\n",
    "print(f\"Model accuracy before feature selection: {pre_selection_score}\")\n",
    "\n",
    "# 2. 使用SelectFromModel基于特征重要性进行特征选择\n",
    "selector = SelectFromModel(rf, threshold=\"mean\")  # 选择特征重要性高于平均值的特征\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# 获取选择的特征\n",
    "selected_features = selector.get_support(indices=True)\n",
    "selected_feature_names = X.columns[selected_features]\n",
    "\n",
    "# 打印被选择的特征名称\n",
    "print(\"Selected features:\")\n",
    "print(selected_feature_names)\n",
    "\n",
    "# 提取选择后的特征\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# 3. 特征选择后的模型\n",
    "# 使用选择后的特征重新训练模型\n",
    "rf_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# 评估特征选择后的模型性能\n",
    "post_selection_score = rf_selected.score(X_test_selected, y_test)\n",
    "print(f\"Model accuracy after feature selection: {post_selection_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 1: 加载数据\n",
    "df = pd.read_csv('../data/processed/merged_data_Y2.csv')  # 请根据需要调整路径\n",
    "X = df.drop(['DaysInHospital', 'MemberID'], axis=1)  # X是所有的特征，移除标签列和MemberID列\n",
    "y = df['DaysInHospital']  # y是目标标签DaysInHospital列\n",
    "\n",
    "# Step 2: 实现k折交叉验证\n",
    "def k_fold_cross_validation(X, y, k, model):\n",
    "    \"\"\"\n",
    "    实现k折交叉验证。\n",
    "    \n",
    "    参数：\n",
    "    X：特征数据集。\n",
    "    y：标签数据集。\n",
    "    k：折数（k-fold的k）。\n",
    "    model：要训练的模型（在每个折上训练的模型）。\n",
    "\n",
    "    返回值：\n",
    "    返回均方误差(MSE)的平均值和标准差。\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # 设置随机种子，保证实验结果可复现\n",
    "    fold_size = len(X) // k  # 每折的大小，数据集的长度除以k\n",
    "    indices = np.random.permutation(len(X))  # 将数据集的索引随机打乱\n",
    "    mse_scores = []  # 用于存储每一折的MSE\n",
    "\n",
    "    # 进行k折交叉验证\n",
    "    for i in range(k):\n",
    "        val_indices = indices[i * fold_size: (i + 1) * fold_size]  # 当前验证集的索引\n",
    "        train_indices = np.concatenate([indices[:i * fold_size], indices[(i + 1) * fold_size:]])  # 剩余部分作为训练集\n",
    "\n",
    "        X_train, X_val = X.iloc[train_indices], X.iloc[val_indices]  # 根据索引分割训练集和验证集\n",
    "        y_train, y_val = y.iloc[train_indices], y.iloc[val_indices]\n",
    "\n",
    "        # 在训练集上训练模型\n",
    "        model.fit(X_train, y_train)\n",
    "        # 预测验证集\n",
    "        y_pred = model.predict(X_val)\n",
    "        # 计算验证集的均方误差\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "\n",
    "    # 返回均方误差的均值和标准差\n",
    "    return np.mean(mse_scores), np.std(mse_scores)\n",
    "\n",
    "# Step 3: 实现嵌套交叉验证\n",
    "def nested_cross_validation(X, y, outer_k=5, inner_k=3, param_grid=None):\n",
    "    \"\"\"\n",
    "    实现嵌套交叉验证，用于超参数调优和模型评估。\n",
    "    \n",
    "    参数：\n",
    "    X：特征数据集。\n",
    "    y：标签数据集。\n",
    "    outer_k：外层k折交叉验证的折数。\n",
    "    inner_k：内层k折交叉验证的折数，用于超参数调优。\n",
    "    param_grid：超参数网格，默认为None，如果没有指定将使用默认的参数网格。\n",
    "\n",
    "    返回值：\n",
    "    返回外层验证集上均方误差(MSE)的平均值和标准差。\n",
    "    \"\"\"\n",
    "    if param_grid is None:\n",
    "        # 如果没有指定超参数网格，使用默认参数\n",
    "        param_grid = {'n_estimators': [10, 50], 'max_depth': [5, 10, None]}\n",
    "\n",
    "    outer_mse_scores = []  # 存储外层验证集的MSE\n",
    "\n",
    "    np.random.seed(42)  # 设置随机种子，保证实验结果可复现\n",
    "    indices = np.random.permutation(len(X))  # 随机打乱数据集索引\n",
    "    fold_size_outer = len(X) // outer_k  # 外层每折的大小\n",
    "\n",
    "    # 进行外层k折交叉验证\n",
    "    for i in range(outer_k):\n",
    "        # 外层的验证集索引\n",
    "        val_indices_outer = indices[i * fold_size_outer:(i + 1) * fold_size_outer]\n",
    "        # 外层的训练集索引\n",
    "        train_indices_outer = np.concatenate([indices[:i * fold_size_outer], indices[(i + 1) * fold_size_outer:]])\n",
    "\n",
    "        X_train_outer, X_val_outer = X.iloc[train_indices_outer], X.iloc[val_indices_outer]  # 根据索引分割外层训练集和验证集\n",
    "        y_train_outer, y_val_outer = y.iloc[train_indices_outer], y.iloc[val_indices_outer]\n",
    "\n",
    "        # 内层交叉验证进行超参数选择\n",
    "        best_mse = float('inf')  # 记录当前最好的MSE\n",
    "        best_params = None  # 记录当前最优的超参数组合\n",
    "\n",
    "        # 遍历超参数网格，进行内层k折交叉验证\n",
    "        for n_estimators in param_grid['n_estimators']:\n",
    "            for max_depth in param_grid['max_depth']:\n",
    "                model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "\n",
    "                # 在内层进行k折交叉验证\n",
    "                mean_mse, _ = k_fold_cross_validation(X_train_outer, y_train_outer, inner_k, model)\n",
    "\n",
    "                # 如果当前组合的MSE优于之前的结果，更新最佳参数\n",
    "                if mean_mse < best_mse:\n",
    "                    best_mse = mean_mse\n",
    "                    best_params = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "        # 使用最优超参数在外层训练集上训练最终模型\n",
    "        final_model = RandomForestRegressor(**best_params, random_state=42)\n",
    "        final_model.fit(X_train_outer, y_train_outer)\n",
    "\n",
    "        # 在外层验证集上评估模型表现\n",
    "        y_pred_outer = final_model.predict(X_val_outer)\n",
    "        mse_outer = mean_squared_error(y_val_outer, y_pred_outer)  # 计算MSE\n",
    "        outer_mse_scores.append(mse_outer)\n",
    "\n",
    "    # 返回外层验证集MSE的均值和标准差\n",
    "    return np.mean(outer_mse_scores), np.std(outer_mse_scores)\n",
    "\n",
    "# Step 4: 进行20次独立实验，并计算均值和方差\n",
    "def run_multiple_experiments(X, y, repetitions=20, outer_k=5, inner_k=3, param_grid=None):\n",
    "    \"\"\"\n",
    "    执行多次嵌套交叉验证实验，并计算每次实验的MSE均值和方差。\n",
    "    \n",
    "    参数：\n",
    "    X：特征数据集。\n",
    "    y：标签数据集。\n",
    "    repetitions：独立实验的次数。\n",
    "    outer_k：外层k折交叉验证的折数。\n",
    "    inner_k：内层k折交叉验证的折数，用于超参数调优。\n",
    "    param_grid：超参数网格，默认为None，如果没有指定将使用默认的参数网格。\n",
    "\n",
    "    返回值：\n",
    "    返回所有实验的MSE均值和方差。\n",
    "    \"\"\"\n",
    "    mse_results = []  # 存储每次实验的MSE结果\n",
    "    for i in range(repetitions):\n",
    "        print(f\"Running repetition {i+1}/{repetitions}\")\n",
    "        # 运行嵌套交叉验证，计算MSE\n",
    "        mean_mse, std_mse = nested_cross_validation(X, y, outer_k=outer_k, inner_k=inner_k, param_grid=param_grid)\n",
    "        mse_results.append(mean_mse)\n",
    "\n",
    "    # 返回所有实验的MSE均值和方差\n",
    "    return np.mean(mse_results), np.std(mse_results)\n",
    "\n",
    "# Step 5: 执行20次嵌套交叉验证实验\n",
    "mean_mse, std_mse = run_multiple_experiments(X, y, repetitions=20)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Mean MSE after 20 repetitions: {mean_mse}\")\n",
    "print(f\"Standard deviation of MSE after 20 repetitions: {std_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 假设df是数据集，DaysInHospital是标签列，MemberID不参与训练\n",
    "df = pd.read_csv('../data/processed/merged_data_Y2.csv')  # 请根据需要调整路径\n",
    "X = df.drop(['DaysInHospital', 'MemberID'], axis=1)\n",
    "y = df['DaysInHospital']\n",
    "\n",
    "# 自定义实现交叉验证\n",
    "def cross_val_score_manual(X, y, model, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    mse_scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mse_scores.append(mse)\n",
    "    \n",
    "    return np.mean(mse_scores), np.std(mse_scores)\n",
    "\n",
    "# 超参数调优的函数，遍历不同的超参数组合\n",
    "def grid_search_manual(X, y, param_grid, k=5):\n",
    "    best_params = None\n",
    "    best_score = float('inf')\n",
    "    \n",
    "    for n_estimators in param_grid['n_estimators']:\n",
    "        for max_depth in param_grid['max_depth']:\n",
    "            model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "            mean_mse, std_mse = cross_val_score_manual(X, y, model, k)\n",
    "            \n",
    "            print(f\"n_estimators: {n_estimators}, max_depth: {max_depth}, Mean MSE: {mean_mse}, Std MSE: {std_mse}\")\n",
    "            \n",
    "            if mean_mse < best_score:\n",
    "                best_score = mean_mse\n",
    "                best_params = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "    \n",
    "    return best_params, best_score\n",
    "\n",
    "# 嵌套交叉验证\n",
    "def nested_cross_val(X, y, param_grid, outer_k=5, inner_k=5, repetitions=20):\n",
    "    outer_kf = KFold(n_splits=outer_k, shuffle=True, random_state=42)\n",
    "    all_mse_scores = []\n",
    "\n",
    "    for i in range(repetitions):\n",
    "        mse_scores = []\n",
    "        \n",
    "        for train_index, test_index in outer_kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            # 在训练集上进行内层交叉验证以找到最佳超参数\n",
    "            best_params, _ = grid_search_manual(X_train, y_train, param_grid, inner_k)\n",
    "            \n",
    "            # 使用最佳超参数训练最终模型并在测试集上评估\n",
    "            best_model = RandomForestRegressor(**best_params, random_state=42)\n",
    "            best_model.fit(X_train, y_train)\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            \n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mse_scores.append(mse)\n",
    "        \n",
    "        all_mse_scores.append(np.mean(mse_scores))\n",
    "        print(f\"Repetition {i+1}/{repetitions}: Mean MSE = {np.mean(mse_scores)}\")\n",
    "    \n",
    "    return np.mean(all_mse_scores), np.std(all_mse_scores)\n",
    "\n",
    "# 定义超参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# 进行嵌套交叉验证，20次独立重复实验\n",
    "mean_mse, std_mse = nested_cross_val(X, y, param_grid, outer_k=5, inner_k=5, repetitions=20)\n",
    "\n",
    "print(f\"Nested Cross-Validation Mean MSE: {mean_mse} ± {std_mse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
